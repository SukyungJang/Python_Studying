{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kqztgijx4rLZ"
      },
      "source": [
        "# 1. Working with data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "a4tcV-gU3pFX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader # Dataset을 둘러싸고 반복 가능한 객체로 만듦\n",
        "from torchvision import datasets # 샘플과 해당하는 레이블 저장\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AK86psWr45Z9"
      },
      "source": [
        "PyTorch는 TorchText, TorchVision, TorchAudio와 같은 도메인별 라이브러리를 제공하는데 이들은 모두 데이터셋을 포함하고 있습니다. 이 튜토리얼에서는 TorchVision 데이터셋을 사용할 것입니다. <br/>\n",
        "<br/>\n",
        "\n",
        "torchvision.datasets 모듈은 CIFAR, COCO와 같은 다양한 실제 비전 데이터에 대한 Dataset 객체를 포함하고 있습니다(전체 목록은 여기에서 확인할 수 있습니다.). 이 튜토리얼에서는 FashionMNIST 데이터셋을 사용합니다. TorchVision 데이터셋은 transform과 target_transform 두 가지 인수를 포함하고 있어, 각각 샘플과 레이블을 수정하는 데 사용됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji2z-_nZ4fCc",
        "outputId": "0e5894f4-74f9-4969-ea78-177225364179"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26421880/26421880 [00:00<00:00, 117538735.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 9389069.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 64795928.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 16333038.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root = \"data\", # 데이터 저장 경로 지정\n",
        "    train = True, # 훈련 데이터를 다운로드합니다.\n",
        "    download = True, # 데이터를 인터넷에서 다운로드합니다.\n",
        "    transform = ToTensor(), # 데이터를 텐서 형태로 변환합니다.\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = ToTensor(),\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UXqmcMe66G-c"
      },
      "source": [
        "Dataset을 DataLoader의 인수로 전달합니다. 이는 데이터셋을 반복 가능한(iterable) 객체로 감싸며, 자동 배치, 샘플링, 셔플링 및 다중 프로세스 데이터 로딩을 지원합니다. 여기에서는 배치 크기를 64로 정의하였으므로, 데이터로더의 각 요소는 64개의 특징(feature)과 레이블(label)로 구성된 배치를 반환할 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxWArazH50J3",
        "outputId": "fb9987d3-d124-4199-efd2-610a947e4a87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64 # 배치 크기\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size = batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size = batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "  print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "  print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "  break"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qhFiI5Y78MHi"
      },
      "source": [
        "배치 크기는 데이터를 미니배치(minibatch)로 나누는 데 사용되는 값입니다. 데이터를 한 번에 모두 처리하는 것이 아니라 작은 미니배치로 나누어 처리하면 몇 가지 이점이 있습니다.\n",
        "- 메모리 효율성: 대용량 데이터셋의 경우 전체 데이터를 한 번에 메모리에 로드하는 것은 메모리 부담이 될 수 있습니다. 배치 크기를 작게 설정하면 각 배치만큼의 메모리만 사용하므로 메모리 사용이 효율적입니다.\n",
        "- 가속화된 학습: GPU를 사용하는 경우, 배치 처리를 통해 병렬 계산을 수행할 수 있습니다. 배치 크기가 클수록 GPU의 병렬 처리 능력을 최대한 활용할 수 있습니다. 이를 통해 학습 속도를 향상시킬 수 있습니다.\n",
        "- 일반화 능력 향상: 미니배치를 사용하면 데이터의 다양성을 확보할 수 있습니다. 다양한 데이터 샘플이 포함된 미니배치를 사용하면 모델이 보다 일반화된 패턴을 학습할 수 있습니다.\n",
        "<br/>\n",
        "\n",
        "또한, 배치 크기는 하이퍼파라미터로서 조정이 가능하며, 최적의 배치 크기는 문제와 데이터에 따라 다를 수 있습니다. 일반적으로는 실험과 검증을 통해 적절한 배치 크기를 찾게 됩니다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GqWKmDB79A0o"
      },
      "source": [
        "# 2. Creating Models\n",
        "PyTorch에서 신경망을 정의하기 위해, nn.Module을 상속한 클래스를 생성합니다. 신경망의 층(layer)들은 init 함수에서 정의하고, 데이터가 신경망을 통과하는 방식은 forward 함수에서 지정합니다. 신경망 연산을 가속화하기 위해, GPU나 MPS(모델 병렬 처리)가 사용 가능한 경우에는 해당 장치로 신경망을 이동시킵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEqWPb357cfz",
        "outputId": "83891d52-2a67-4a65-91d4-ae5205eda10c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\" # GPU가 사용 가능한 경우 CUDA 장치 선택\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\" # MPS가 사용 가능한 경우 MPS 장치 선택\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\" # 그 외의 경우 CPU 장치 선택\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten() # 2D 이미지를 1D로 평탄화\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512), # 입력 크기: 28*28, 출력 크기: 512\n",
        "            nn.ReLU(), # ReLU 활성화 함수\n",
        "            nn.Linear(512, 512), # 입력 크기: 512, 출력 크기: 512\n",
        "            nn.ReLU(), # ReLU 활성화 함수\n",
        "            nn.Linear(512, 10) # 입력 크기: 512, 출력 크기: 10 (클래스 개수)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x) # 입력을 평탄화\n",
        "        logits = self.linear_relu_stack(x) # 평탄화된 입력을 신경망에 통과\n",
        "        return logits\n",
        "\n",
        "# 모델 인스턴스 생성 및 장치로 이\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bu3m89QCAS4r"
      },
      "source": [
        "# 3. Optimizing the Model Parameters\n",
        "모델을 학습시키기 위해서는 손실 함수(loss function)와 옵티마이저(optimizer)가 필요합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HtKcaWOX_PyO"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uaum7FY1AtZ7"
      },
      "source": [
        "- **loss_fn**: 손실 함수로 CrossEntropyLoss를 사용합니다. 이 함수는 다중 클래스 분류 문제에 적합한 손실 함수입니다.\n",
        "- **optimizer**: 옵티마이저로 SGD(Stochastic Gradient Descent)를 사용합니다. 모델의 파라미터를 업데이트하기 위해 경사하강법을 활용합니다. 학습률(learning rate)은 1e-3로 설정되었습니다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3TedwRjBJ4Y"
      },
      "source": [
        "한 번의 학습 루프에서 모델은 학습 데이터셋에 대한 예측을 수행하고 (배치 단위로 제공됨), 예측 오차를 역전파하여 모델의 파라미터를 조정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0iKJHzZBAl9B"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset) # 데이터셋의 총 샘플 개수\n",
        "  model.train() # 모델을 학습 모드로 설정\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device) # 데이터와 레이블을 GPU로 이동\n",
        "\n",
        "    # 예측 오차 계산\n",
        "    pred = model(X) # 모델을 사용하여 예측 수행\n",
        "    loss = loss_fn(pred, y) # 예측과 실제 레이블 사이의 손실 계산\n",
        "\n",
        "    # 역전파\n",
        "    loss.backward() # 손실에 대한 역전파를 수행\n",
        "    optimizer.step() # 옵티마이저를 사용하여 모델의 파라미터 업데이트\n",
        "    optimizer.zero_grad() # 모델의 변화도를 초기화\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lPR6smR8C7-r"
      },
      "source": [
        "모델의 성능을 확인하기 위해 테스트 데이터셋을 사용하여 모델을 평가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TlieSX-sCCTK"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset) # 테스트 데이터셋의 샘플 개수\n",
        "  num_batches = len(dataloader) # 배치의 개수\n",
        "  model.eval() # 모델을 평가 모드로 설정\n",
        "  test_loss, correct = 0, 0 # 테스트 손실과 정확도 초기화\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device) # 데이터를 디바이스(GPU 또는 CPU)로 이동\n",
        "      pred = model(X) # 모델에 입력을 전달하여 예측 수행\n",
        "      test_loss += loss_fn(pred, y). item() # 손실 값을 누적\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item() # 정확한 예측 수를 누적\n",
        "  test_loss /= num_batches # 평균 손실 계산\n",
        "  correct /= size # 정확도 계싼\n",
        "  print(f\"Test Error: \\n Accuracy: {(100 * correct):>0.1f}% Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G-pLPEtNEvQu"
      },
      "source": [
        "훈련 과정은 여러 번의 반복(epoch)을 거쳐 진행됩니다. 각 에포크에서 모델은 더 나은 예측을 위해 매개변수를 학습합니다. 각 에포크마다 모델의 정확도와 손실을 출력합니다. 정확도는 증가하고 손실은 감소하는 것을 기대합니다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "74FP1mmoE-qt"
      },
      "source": [
        "# 4. Saving Models\n",
        "모델을 저장하는 일반적인 방법은 내부 상태 딕셔너리(모델 매개변수를 포함하는)를 직렬화하는 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjMMmKQ8DuOS",
        "outputId": "9bb3b859-f8a8-43a8-dec3-8ffe2a4384fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mE1sgW4yFooZ"
      },
      "source": [
        "# 5. Loading Models\n",
        "모델을 로드하는 과정은 모델 구조를 재생성하고 그 상태 사전을 모델에 로드하는 것을 포함합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9lBKN4NFP9H",
        "outputId": "1638da77-5733-4d55-ab5e-08ffdc183ffa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_Zuf-Q0F7Lm",
        "outputId": "d1227cb1-eaf6-486a-b4a6-b513ada1d6aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: \"Sneaker\", Actual: \"Ankle boot\"\n"
          ]
        }
      ],
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval() # 모델을 평가 모드로 설정합니다.\n",
        "x, y = test_data[0][0], test_data[0][1] # 테스트 데이터에서 예시 데이터를 가져옵니다.\n",
        "with torch.no_grad():\n",
        "  x = x.to(device) # 데이터를 디바이스(GPU 또는 CPU)로 이동합니다.\n",
        "  pred = model(x) # 모델에 데이터를 전달하여 예측 수행\n",
        "  predicted, actual = classes[pred[0].argmax(0)], classes[y] # 예측 결과와 실제 결과를 가져옴\n",
        "  print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"') # 예측 결과와 실제 결과 출력"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
