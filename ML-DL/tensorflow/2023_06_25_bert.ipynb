{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy-3dCf3svjK"
      },
      "source": [
        "# 1. BERT소개\n",
        "**BERT**는 2018년에 개발된 자연어 처리 모델로, 트랜스포머(Transformer) 아키텍처를 기반으로 한다. BERT는 딥 러닝 기술 중 하나인 전이 학습(Transfer Learning)을 사용하여 대규모 텍스트 데이터로 사전훈련(pre-training)된 후 다양한 자연어 처리 작업에 적용할 수 있다는 점에서 혁신적인 모델로 인정받고 있다.  <br/>\n",
        "<br/>\n",
        "\n",
        "BERT의 핵심 아이디어는 양방향 언어 모델링(bidirectional language modeling)과 마스킹된 언어 모델링(masked language modeling)을 조합하여 전체 문맥을 고려한 단어의 임베딩을 학습하는 것이다. 이를 위해 BERT는 입력 문장을 여러 개의 토큰(token)으로 분리하고, 각 토큰의 임베딩 값을 학습시킨다. 임베딩 값은 다른 자연어 처리 작업에 사용될 수 있다. <br/>\n",
        "<br/>\n",
        "\n",
        "BERT는 사전훈련과 세부 작업 fine-tuning 두 단계로 구성된다. 사전훈련 단계에서는 대량의 텍스트 데이터로 모델을 사전훈려하여 언어적인 특성을 학습한다. 그리고 fine-tuning 단계에서는 특정 자연어 처리 작업에 맞게 BERT를 세부 조정하여 해당 작업을 수행한다. 예를 들어, 문장 분류, 개체명 인식, 질의 응답 등 다양한 작업에 BERT를 적용할 수 있다. <br/>\n",
        "<br/>\n",
        "\n",
        "BERT는 자연어 처리 분야에서 다양한 작업에서 높은 성능을 보여주었으며, 이후 많은 연구와 응용에서 활발하게 사용되고 있다. BERT를 비롯한 전이 학습 모델들은 텍스트 이해와 자연어 처이의 다양한 과제를 해결하는 데 큰 도움을 주고 있으며, 자연어 처리 분야에서 혁신적인 발전을 이끌고 있는 중요한 모델 중 하나다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q9kcvSys6cr"
      },
      "source": [
        "# 2. 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yVgCAs7stJt",
        "outputId": "12097935-814a-4e5d-8f3b-bd70faffafca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyyaml (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U tensorflow-text\n",
        "!pip install -q tf-models-official"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgjAVS1bs541",
        "outputId": "fe312a0e-7b02-4b7e-bb3f-3ee1ef1bfb06"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7E2oGFvbtS9G"
      },
      "source": [
        "# 3. 감정 분석\n",
        "이 노트북은 텍스트를 기반으로 양 또는 음으로 분류 영화 리뷰에 감정 분석 모델을 훈련한다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPHsQblGtg0j"
      },
      "source": [
        "## 3-1. IMDB 데이터세트 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jl9K2S2bte3J"
      },
      "outputs": [],
      "source": [
        "url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "\n",
        "dataset = tf.keras.utils.get_file('aclImdb_v1.tar.gz', url,\n",
        "                                  untar = True, cache_dir = '.',\n",
        "                                  cache_subdir = '')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "\n",
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "\n",
        "# remove unused folders to make it easier to load the data\n",
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BtvtKpDHult4"
      },
      "source": [
        "**shutil.rmtree(remove_dir)**: 지정한 디렉토리와 그 하위 디렉토리가 모두 삭제됩니다. 삭제 작업은 재귀적으로 이루어지므로, 디렉토리 내에 포함된 모든 파일과 하위 디렉토리가 삭제됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHPx6EcDuO5_",
        "outputId": "201d4e6b-9aa1-48d1-c883-ae84b35dcd4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE # 데이터셋 성능 향상을 위한 매개변수\n",
        "batch_size = 32 # 데이터를 미니배치로 처리할 때 배치 크기\n",
        "seed = 42 # 난수 발생 시트, 재현성을 위해 사용\n",
        "\n",
        "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size = batch_size,\n",
        "    validation_split = 0.2, # 데이터 분할 비율 80% 학습 데이터 사용\n",
        "    subset = 'training', # 사용할 하위셋(subset)\n",
        "    seed = seed\n",
        ")\n",
        "\n",
        "class_names = raw_train_ds.class_names # 클래스(레이블)의 이름을 가져옴\n",
        "train_ds = raw_train_ds.cache().prefetch(buffer_size = AUTOTUNE) # 데이터를 메모리나 로컬 디스크에 캐시하여 데이터 읽기 성능 향상\n",
        "\n",
        "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size = batch_size,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'validation',\n",
        "    seed = seed\n",
        ")\n",
        "\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/test',\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "test_ds = test_ds.cache().prefetch(buffer_size = AUTOTUNE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gBelxyorwYya"
      },
      "source": [
        "몇 가지 리뷰를 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTt8UbIMvqn-",
        "outputId": "200113f9-9d2d-4779-b293-11217d756599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review: b'\"Pandemonium\" is a horror movie spoof that comes off more stupid than funny. Believe me when I tell you, I love comedies. Especially comedy spoofs. \"Airplane\", \"The Naked Gun\" trilogy, \"Blazing Saddles\", \"High Anxiety\", and \"Spaceballs\" are some of my favorite comedies that spoof a particular genre. \"Pandemonium\" is not up there with those films. Most of the scenes in this movie had me sitting there in stunned silence because the movie wasn\\'t all that funny. There are a few laughs in the film, but when you watch a comedy, you expect to laugh a lot more than a few times and that\\'s all this film has going for it. Geez, \"Scream\" had more laughs than this film and that was more of a horror film. How bizarre is that?<br /><br />*1/2 (out of four)'\n",
            "Label: 0 (neg)\n",
            "Review: b\"David Mamet is a very interesting and a very un-equal director. His first movie 'House of Games' was the one I liked best, and it set a series of films with characters whose perspective of life changes as they get into complicated situations, and so does the perspective of the viewer.<br /><br />So is 'Homicide' which from the title tries to set the mind of the viewer to the usual crime drama. The principal characters are two cops, one Jewish and one Irish who deal with a racially charged area. The murder of an old Jewish shop owner who proves to be an ancient veteran of the Israeli Independence war triggers the Jewish identity in the mind and heart of the Jewish detective.<br /><br />This is were the flaws of the film are the more obvious. The process of awakening is theatrical and hard to believe, the group of Jewish militants is operatic, and the way the detective eventually walks to the final violent confrontation is pathetic. The end of the film itself is Mamet-like smart, but disappoints from a human emotional perspective.<br /><br />Joe Mantegna and William Macy give strong performances, but the flaws of the story are too evident to be easily compensated.\"\n",
            "Label: 0 (neg)\n",
            "Review: b'Great documentary about the lives of NY firefighters during the worst terrorist attack of all time.. That reason alone is why this should be a must see collectors item.. What shocked me was not only the attacks, but the\"High Fat Diet\" and physical appearance of some of these firefighters. I think a lot of Doctors would agree with me that,in the physical shape they were in, some of these firefighters would NOT of made it to the 79th floor carrying over 60 lbs of gear. Having said that i now have a greater respect for firefighters and i realize becoming a firefighter is a life altering job. The French have a history of making great documentary\\'s and that is what this is, a Great Documentary.....'\n",
            "Label: 1 (pos)\n"
          ]
        }
      ],
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "  for i in range(3):\n",
        "    print(f'Review: {text_batch.numpy()[i]}')\n",
        "    label = label_batch.numpy()[i]\n",
        "    print(f'Label: {label} ({class_names[label]})')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "E-RIzTWwwuDT"
      },
      "source": [
        "# 4. TensorFlow Hub에서 모델 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBPOTatlwp9R",
        "outputId": "ba006321-b7d4-4491-ba37-05cd53ad4b7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ]
        }
      ],
      "source": [
        "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'\n",
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/google/electra_small/2',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/google/electra_base/2',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1XZ6Vougw_F7"
      },
      "source": [
        "# 5. 전처리 모델\n",
        "텍스트 입력은 BERT에 입력되기 전에 숫자 토큰 ID로 변환되고 여러 텐서로 정렬되어야 합니다. TensorFLow Hub은 위에서 설명한 각 BERT 모델에 대해 일치하는 전처리 모델을 제공하며, 이는 TF.text 라이브러리의 TF 작업을 사용하여 이 변환을 구현합니다. 텍스트를 사전 처리하기 위해 TensorFLow 모델 외부에서 순수 Python 코드를 실행할 필요는 없습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CvXRMJa5w3nR"
      },
      "outputs": [],
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hy3FO4YAxco7"
      },
      "source": [
        "일부 텍스트에 대한 전처리 모델을 시도하고 출력을 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trznptBMxcJG",
        "outputId": "8a471b3d-3206-4fe0-e10e-1ebc8c09c662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keys       : ['input_word_ids', 'input_type_ids', 'input_mask']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "text_test = ['this is such an amazing movie!']\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VIC3wkv0x4SH"
      },
      "source": [
        "# 6. BERT 모델 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "t1BOYD2oxsVm"
      },
      "outputs": [],
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuFnIHWVyCxS",
        "outputId": "8c41cf0c-3417-4bfe-f207-b58f4b33cc82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Pooled Outputs Shape:(1, 512)\n",
            "Pooled Outputs Values:[ 0.7626294   0.9928099  -0.18611868  0.3667384   0.15233697  0.6550447\n",
            "  0.9681154  -0.94862723  0.00216173 -0.9877732   0.06842681 -0.97630596]\n",
            "Sequence Outputs Shape:(1, 128, 512)\n",
            "Sequence Outputs Values:[[-0.2894635   0.34321314  0.33231482 ...  0.21300751  0.7102076\n",
            "  -0.0577114 ]\n",
            " [-0.2874215   0.31981048 -0.23018587 ...  0.5845506  -0.21329802\n",
            "   0.72692144]\n",
            " [-0.6615703   0.68876755 -0.87433    ...  0.10877246 -0.26173204\n",
            "   0.47855428]\n",
            " ...\n",
            " [-0.22561137 -0.2892561  -0.07064435 ...  0.47566015  0.8327713\n",
            "   0.4002532 ]\n",
            " [-0.29824218 -0.27473158 -0.05450481 ...  0.4884971   1.0955353\n",
            "   0.18163383]\n",
            " [-0.4437822   0.00930763  0.07223707 ...  0.1729007   1.1833245\n",
            "   0.07898022]]\n"
          ]
        }
      ],
      "source": [
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GpaA9yKByuAq"
      },
      "source": [
        "# 7. 모델 정의\n",
        "전처리 모델, 선택된 BERT 모델, 하나의 Dense 및 Dropout 레이어를 사용하여 매우 간단한 미세 조정 모델을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Dk2aAHS4yJoE"
      },
      "outputs": [],
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape = (), dtype = tf.string, name = 'text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name = 'preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable = True, name = 'BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.1)(net)\n",
        "  net = tf.keras.layers.Dense(1, activation = None, name = 'classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9U1UItPPzr2i"
      },
      "source": [
        "**text_input**: 텍스트 입력을 받기 위한 TensorFlow Keras의 'Input'레이어입니다. <br/>\n",
        "\n",
        "**preprocessing_layer**: 텍스트 데이터를 전처리하기 위한 TensorFlow Hub의 Keras 레이어인 'preprocessing'입니다. 이 레이어는 입력된 텍스트를 전처리하여 BERT 모델에 입력으로 사용할 수 있는 형태로 변환합니다. <br/>\n",
        "\n",
        "**encoder_inputs**: 'preprocessing_layer'를 사용하여 전처리된 텍스트를 입력으로 받는 레이어입니다. <br/>\n",
        "\n",
        "**encoder**: TensorFlow Hub의 Keras 레이어인 'BERT_encoder'로, 사전 훈련된 BERT 모델을 가져와서 전처리된 입력을 BERT 인코딩으로 변환합니다. <br/>\n",
        "\n",
        "**output**: 'encoder'를 통과한 결과입니다.<br/>\n",
        "\n",
        "**net**: 'output'에서 추출한 BERT 모델의 'pooled_output'을 나타냅니다. 'pooled_output'은 문장 수준의 표현을 담고 있습니다. **net**에는 10%의 드롭아웃(Dropout)을 적용한 후, 하나의 출력 뉴런만 있는 밀집(Dense) 레이어인 'classifier'를 추가합니다. <br/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4svfgz4ze4A",
        "outputId": "a1155feb-d01c-4831-b1de-179078e07182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.4210528]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "classifier_model = build_classifier_model()\n",
        "bert_raw_result = classifier_model(tf.constant(text_test))\n",
        "print(tf.sigmoid(bert_raw_result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "kq0LffS_1SP3",
        "outputId": "581596fd-5abe-4476-a6a1-2cfa17d05e91"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델 구조\n",
        "tf.keras.utils.plot_model(classifier_model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jgir6Qkp1g0W"
      },
      "source": [
        "# 8. 모델 교육\n",
        "이제 전처리 모듈, BERT 인코더, 데이터 및 분류기를 포함하여 모델을 훈련하는 데 필요한 모든 부분이 있습니다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GA-8Kf6G1mUe"
      },
      "source": [
        "## 8-1. 손실 기능\n",
        "이 이진 분류 문제는 상기 모델은 확률 (단일 단위 층)을 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2MMo4pAF1X1g"
      },
      "outputs": [],
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
        "metrics = tf.metrics.BinaryAccuracy()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "A-7XloPu112l"
      },
      "source": [
        "## 8-2. 옵티마이저\n",
        "미세 조정을 위해 BERT가 원래 훈련된 것과 동일한 최적화 프로그램인 Adam을 사용하겠습니다. 이 최적화는 예측 손실을 최소화하는 것으로 알려져있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "eU4JXikD10cE"
      },
      "outputs": [],
      "source": [
        "epochs = 5 # 훈련할 에포크의 수\n",
        "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy() # 한 에포크 동안 수행할 스탭 수\n",
        "num_train_steps = steps_per_epoch * epochs # 전체 훈련 스텝의 수\n",
        "num_warmup_steps = int(0.1 * num_train_steps) # 초기 학습률을 점진적으로 증가시키는 웜업 스텝의 수\n",
        "\n",
        "init_lr = 3e-5 # 초기 학습률의 값\n",
        "optimizer = optimization.create_optimizer(init_lr = init_lr,\n",
        "                                          num_train_steps = num_train_steps,\n",
        "                                          num_warmup_steps = num_warmup_steps,\n",
        "                                          optimizer_type = 'adamw')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Iikyw-fZ2ee5"
      },
      "source": [
        "## 8-3. BERT 모델 로드 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gkyX_dLR2dyn"
      },
      "outputs": [],
      "source": [
        "classifier_model.compile(optimizer = optimizer,\n",
        "                         loss = loss,\n",
        "                         metrics = metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmhCDBt73rSw"
      },
      "outputs": [],
      "source": [
        "print(f'Training model with {tfhub_handle_encoder}')\n",
        "history = classifier_model.fit(x = train_ds,\n",
        "                               validation_data = val_ds,\n",
        "                               epochs = epochs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd6tTeq63Pv4"
      },
      "source": [
        "## 8-4. 모델 평가\n",
        "모델이 어떻게 작동하는지 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1w6_TOb3pzY"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = classifier_model.evaluate(test_ds)\n",
        "\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RGW9YsMS3no9"
      },
      "source": [
        "## 8-5. 시간 경과에 따른 정확도 및 손실 플로팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjKEBynb3zi0"
      },
      "outputs": [],
      "source": [
        "history_dict = history.history\n",
        "print(history_dict.keys())\n",
        "\n",
        "acc = history_dict['binary_accuracy']\n",
        "val_acc = history_dict['val_binary_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "# r is for \"solid red line\"\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "# plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(epochs, acc, 'r', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kcAGjR1L31JR"
      },
      "source": [
        "훈련시키는 내용은 환경상 어려워 실행하지 않았습니다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rhA_eNcc35dJ"
      },
      "source": [
        "# 9. 참고 문헌\n",
        "<https://www.tensorflow.org/text/tutorials/classify_text_with_bert?hl=ko>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
